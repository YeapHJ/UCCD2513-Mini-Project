{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd2d82b",
   "metadata": {},
   "source": [
    "# Weekly activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6f517e",
   "metadata": {},
   "source": [
    "1. Rotate image by 45 degrees without cropping the sides of the image. (Hint: There are 2 strategies to tackle these problems). Use \"lena.jfif\" as the input image.\n",
    " - Use external libraries imutils.\n",
    " - Modify the transformation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f7352",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e634f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "\n",
    "input_image_path = \"lena.jfif\"\n",
    "image = cv2.imread(input_image_path)\n",
    "\n",
    "(h, w) = image.shape[:2]\n",
    "center = (w // 2, h // 2)\n",
    "\n",
    "angle = 45\n",
    "\n",
    "rotated_image = imutils.rotate_bound(image, angle)\n",
    "\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.imshow(\"Rotated Image\", rotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff09faa",
   "metadata": {},
   "source": [
    "2. Use the images with titles: \"flower.jfif\" and \"native-bee.png\". I want to put flower above an image. If I add two images, it will change color. If I blend it, I get a transparent effect. But I want it to be opaque. If it was a rectangular region, we could use the ROI as we did in the previous section. But flower is not a rectangular region. This is where bitwise operations, like AND, OR, NOT and XOR really come in handy. The associated functions are cv.bitwise_and(), cv.bitwise_or() and cv.bitwise_not(). You need to use cv.threshold function to segment the flower. Please refer to online documentation for more info. The result should resemble the following:\n",
    "bee and flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6750db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "flower_image = cv2.imread(\"flower.jfif\")\n",
    "bee_image = cv2.imread(\"native-bee.png\")\n",
    "\n",
    "gray_flower = cv2.cvtColor(flower_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "thresholded_flower = cv2.threshold(gray_flower, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "background_mask = cv2.bitwise_not(thresholded_flower)\n",
    "\n",
    "resized_flower = cv2.resize(flower_image, (bee_image.shape[1], bee_image.shape[0]))\n",
    "\n",
    "masked_bee = cv2.bitwise_and(bee_image, bee_image, mask=background_mask)\n",
    "final_image = cv2.bitwise_or(masked_bee, resized_flower)\n",
    "\n",
    "cv2.imshow(\"Bee and Flowers\", final_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46b9689",
   "metadata": {},
   "source": [
    "3. Apply custom sharpening kernel of aperture size 3 and 5 as shown below on 'native-bee.png':\n",
    " What can you infer from the outputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e91b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image_path = \"native-bee.png\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "kernel_3x3 = np.array([[-1, -1, -1],\n",
    "                       [-1,  5, -1],\n",
    "                       [-1, -1, -1]])\n",
    "\n",
    "kernel_5x5 = np.array([[-1, -1, -1, -1, -1],\n",
    "                       [-1, -1, -1, -1, -1],\n",
    "                       [-1, -1, 25, -1, -1],\n",
    "                       [-1, -1, -1, -1, -1],\n",
    "                       [-1, -1, -1, -1, -1]])\n",
    "\n",
    "sharpened_image_3x3 = cv2.filter2D(image, -1, kernel_3x3)\n",
    "sharpened_image_5x5 = cv2.filter2D(image, -1, kernel_5x5)\n",
    "\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.imshow(\"Sharpened Image (3x3)\", sharpened_image_3x3)\n",
    "cv2.imshow(\"Sharpened Image (5x5)\", sharpened_image_5x5)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365e27f8",
   "metadata": {},
   "source": [
    "4. Apply different image smoothing techniques (e.g. average filter, Gaussian kernel and median filter) on 'noise_lena.jpg' and display the resulting images after the convolution. Comment on the outcomes and deduce the type of noise present on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e8833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image_path = \"noise_lena.jpg\"\n",
    "image_with_noise = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "average_filtered = cv2.blur(image_with_noise, (3, 3))\n",
    "\n",
    "gaussian_filtered = cv2.GaussianBlur(image_with_noise, (5, 5), 0)\n",
    "\n",
    "median_filtered = cv2.medianBlur(image_with_noise, 3)\n",
    "\n",
    "cv2.imshow(\"Original Image\", image_with_noise)\n",
    "cv2.imshow(\"Average Filtered\", average_filtered)\n",
    "cv2.imshow(\"Gaussian Filtered\", gaussian_filtered)\n",
    "cv2.imshow(\"Median Filtered\", median_filtered)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
